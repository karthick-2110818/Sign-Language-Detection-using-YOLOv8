# 🤟 Sign Language Detection using YOLOv8  

## 📌 Overview  
Sign Language Detection is an AI-powered system that **recognizes and interprets sign language gestures** using deep learning and computer vision techniques. This project utilizes **YOLOv8 (You Only Look Once)** for **real-time hand gesture detection** and classification, making communication more accessible for the hearing-impaired community.  

### 🌟 **Key Features:**  
✅ **Real-time Detection** – Uses YOLOv8 for high-speed and accurate hand sign recognition.  
✅ **Multi-Gesture Support** – Recognizes multiple hand gestures corresponding to sign language alphabets and words.  
✅ **Live Webcam & Video Processing** – Supports both static image recognition and real-time video detection.  
✅ **Custom Model Training** – Train YOLOv8 on a dataset of hand gestures for better accuracy.  
✅ **Integration with Speech/Text Output** – Converts recognized signs into text or speech for effective communication.  

---

## 🛠️ System Requirements  

### **🔧 Software & Libraries**  
1️⃣ **Python 3.x** – Core programming language for the project.  
2️⃣ **Anaconda (Optional)** – Environment management tool.  
3️⃣ **Jupyter Notebook** – Interactive coding and debugging environment.  
4️⃣ **Visual Studio Code (VS Code)** – Alternative IDE for development.  

### **🖥️ Machine Learning & Deep Learning Requirements**  
5️⃣ **PyTorch** – Deep learning framework for model training and inference.  
6️⃣ **YOLOv8 by Ultralytics** – Object detection model used for sign recognition.  
7️⃣ **OpenCV** – Image processing library for handling video streams and real-time detection.  
8️⃣ **CUDA/cuDNN (Optional)** – For GPU acceleration to speed up training and inference.  

**💡 Note:** If you are running on a CPU, YOLOv8 will still function but at a slower speed.  

---


